{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deckbuild Model Training\n",
    "\n",
    "This notebook trains deck completion models using 17lands game data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Download **game data** (not draft data) from [17lands](https://www.17lands.com/public_datasets) into `statistical-drafting/data/17lands/`\n",
    "2. Ensure card data exists in `statistical-drafting/data/cards/`\n",
    "3. Run this notebook to train the deck completion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (restart kernel after running this cell)\n",
    "%pip install torch numpy pandas scikit-learn matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path for local imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import statisticaldeckbuild as sdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration\n",
    "SET_ABBREVIATION = \"FDN\"  # Change to your target set\n",
    "DRAFT_MODE = \"Premier\"     # \"Premier\", \"Trad\", etc.\n",
    "N_HOLDOUT = 1              # Number of cards to hold out for prediction\n",
    "OVERWRITE_DATASET = True   # Set to False to reuse existing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets from game data\n",
    "train_path, val_path = sdb.create_deckbuild_dataset(\n",
    "    set_abbreviation=SET_ABBREVIATION,\n",
    "    draft_mode=DRAFT_MODE,\n",
    "    overwrite=OVERWRITE_DATASET,\n",
    "    n_holdout=N_HOLDOUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = torch.load(train_path, weights_only=False)\n",
    "val_dataset = torch.load(val_path, weights_only=False)\n",
    "\n",
    "print(f\"Training examples: {len(train_dataset)}\")\n",
    "print(f\"Validation examples: {len(val_dataset)}\")\n",
    "print(f\"Number of cards: {len(train_dataset.cardnames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10000, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a single training example\n",
    "partial_deck, available, label = train_dataset[0]\n",
    "\n",
    "print(\"Partial deck cards:\")\n",
    "for i, count in enumerate(partial_deck):\n",
    "    if count > 0:\n",
    "        print(f\"  {train_dataset.cardnames[i]}: {int(count)}\")\n",
    "\n",
    "print(f\"\\nTotal cards in partial deck: {int(partial_deck.sum())}\")\n",
    "print(f\"Available cards to choose from: {int(available.sum())}\")\n",
    "print(f\"Held out card(s): {[train_dataset.cardnames[i] for i in range(len(label)) if label[i] > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network\n",
    "network = sdb.DeckbuildNet(cardnames=train_dataset.cardnames)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in network.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "network, training_info = sdb.train_deckbuild_model(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    network,\n",
    "    experiment_name=f\"{SET_ABBREVIATION}_{DRAFT_MODE}_deckbuild\",\n",
    "    learning_rate=0.03,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "print(\"Training Results:\")\n",
    "for key, value in training_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "model_path = f\"../data/models/{SET_ABBREVIATION}_{DRAFT_MODE}_deckbuild.pt\"\n",
    "network.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "network.eval()\n",
    "\n",
    "# Final evaluation\n",
    "accuracy = sdb.evaluate_deckbuild_model(val_dataloader, network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions for a few examples\n",
    "import torch\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        partial_deck, available, label = val_dataset[i]\n",
    "        \n",
    "        # Get prediction\n",
    "        pred = network(partial_deck.unsqueeze(0).float(), available.unsqueeze(0).float())\n",
    "        pred = pred.squeeze(0)\n",
    "        \n",
    "        # Mask unavailable cards\n",
    "        pred[available == 0] = float('-inf')\n",
    "        \n",
    "        # Get top 5 predictions\n",
    "        top_indices = torch.argsort(pred, descending=True)[:5]\n",
    "        actual_card = [val_dataset.cardnames[j] for j in range(len(label)) if label[j] > 0][0]\n",
    "        \n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"  Actual held-out card: {actual_card}\")\n",
    "        print(f\"  Top 5 predictions:\")\n",
    "        for rank, idx in enumerate(top_indices, 1):\n",
    "            card_name = val_dataset.cardnames[idx]\n",
    "            marker = \" <-- CORRECT\" if card_name == actual_card else \"\"\n",
    "            print(f\"    {rank}. {card_name}{marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Training Pipeline\n",
    "\n",
    "For convenience, you can also use the default pipeline function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run the full pipeline in one call\n",
    "# training_info = sdb.default_deckbuild_pipeline(\n",
    "#     set_abbreviation=\"FDN\",\n",
    "#     draft_mode=\"Premier\",\n",
    "#     overwrite_dataset=True,\n",
    "#     n_holdout=1,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
