{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deckbuilding Interactive Testing\n",
        "\n",
        "This notebook provides interactive testing for the deckbuilding functionality in the statistical drafting library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m  DEPRECATION: Legacy editable install of statisticaldrafting==0.0.1 from file:///Users/danielbrooks/Desktop/Code/statistical-drafting (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the package in development mode\n",
        "%pip install -e .. -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statisticaldrafting as sd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Sample Game Data\n",
        "\n",
        "Let's load some game data to test our deckbuilding functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10000 game records\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>expansion</th>\n",
              "      <th>event_type</th>\n",
              "      <th>draft_id</th>\n",
              "      <th>draft_time</th>\n",
              "      <th>game_time</th>\n",
              "      <th>build_index</th>\n",
              "      <th>match_number</th>\n",
              "      <th>game_number</th>\n",
              "      <th>rank</th>\n",
              "      <th>opp_rank</th>\n",
              "      <th>...</th>\n",
              "      <th>tutored_Zombify</th>\n",
              "      <th>deck_Zombify</th>\n",
              "      <th>sideboard_Zombify</th>\n",
              "      <th>opening_hand_Zul Ashur, Lich Lord</th>\n",
              "      <th>drawn_Zul Ashur, Lich Lord</th>\n",
              "      <th>tutored_Zul Ashur, Lich Lord</th>\n",
              "      <th>deck_Zul Ashur, Lich Lord</th>\n",
              "      <th>sideboard_Zul Ashur, Lich Lord</th>\n",
              "      <th>user_n_games_bucket</th>\n",
              "      <th>user_game_win_rate_bucket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FDN</td>\n",
              "      <td>PremierDraft</td>\n",
              "      <td>c296734752c7449592905c452b88688f</td>\n",
              "      <td>2024-11-12 19:09:18</td>\n",
              "      <td>2024-11-12 19:39:12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>platinum</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FDN</td>\n",
              "      <td>PremierDraft</td>\n",
              "      <td>f4060a8ab54f4a02b0916f3b0d984141</td>\n",
              "      <td>2024-11-12 21:20:12</td>\n",
              "      <td>2024-11-12 21:45:34</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FDN</td>\n",
              "      <td>PremierDraft</td>\n",
              "      <td>f4060a8ab54f4a02b0916f3b0d984141</td>\n",
              "      <td>2024-11-12 21:20:12</td>\n",
              "      <td>2024-11-12 23:00:21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>platinum</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FDN</td>\n",
              "      <td>PremierDraft</td>\n",
              "      <td>690d05dbbf9940f695bb1169553dfca6</td>\n",
              "      <td>2024-11-14 01:58:01</td>\n",
              "      <td>2024-11-14 02:16:27</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>platinum</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FDN</td>\n",
              "      <td>PremierDraft</td>\n",
              "      <td>a65901b9b2c943a0ab4215b5c7d7a591</td>\n",
              "      <td>2024-11-17 21:56:47</td>\n",
              "      <td>2024-11-17 22:16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>platinum</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 1450 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  expansion    event_type                          draft_id  \\\n",
              "0       FDN  PremierDraft  c296734752c7449592905c452b88688f   \n",
              "1       FDN  PremierDraft  f4060a8ab54f4a02b0916f3b0d984141   \n",
              "2       FDN  PremierDraft  f4060a8ab54f4a02b0916f3b0d984141   \n",
              "3       FDN  PremierDraft  690d05dbbf9940f695bb1169553dfca6   \n",
              "4       FDN  PremierDraft  a65901b9b2c943a0ab4215b5c7d7a591   \n",
              "\n",
              "            draft_time            game_time  build_index  match_number  \\\n",
              "0  2024-11-12 19:09:18  2024-11-12 19:39:12            0             1   \n",
              "1  2024-11-12 21:20:12  2024-11-12 21:45:34            0             1   \n",
              "2  2024-11-12 21:20:12  2024-11-12 23:00:21            3             2   \n",
              "3  2024-11-14 01:58:01  2024-11-14 02:16:27            0             1   \n",
              "4  2024-11-17 21:56:47  2024-11-17 22:16:23            0             1   \n",
              "\n",
              "   game_number      rank  opp_rank  ... tutored_Zombify deck_Zombify  \\\n",
              "0            1  platinum       NaN  ...               0            0   \n",
              "1            1       NaN       NaN  ...               0            0   \n",
              "2            1  platinum       NaN  ...               0            0   \n",
              "3            1  platinum       NaN  ...               0            0   \n",
              "4            1  platinum       NaN  ...               0            0   \n",
              "\n",
              "   sideboard_Zombify  opening_hand_Zul Ashur, Lich Lord  \\\n",
              "0                  0                                  0   \n",
              "1                  0                                  0   \n",
              "2                  0                                  0   \n",
              "3                  0                                  0   \n",
              "4                  0                                  0   \n",
              "\n",
              "   drawn_Zul Ashur, Lich Lord tutored_Zul Ashur, Lich Lord  \\\n",
              "0                           0                            0   \n",
              "1                           0                            0   \n",
              "2                           0                            0   \n",
              "3                           0                            0   \n",
              "4                           0                            0   \n",
              "\n",
              "   deck_Zul Ashur, Lich Lord  sideboard_Zul Ashur, Lich Lord  \\\n",
              "0                          0                               0   \n",
              "1                          0                               0   \n",
              "2                          0                               0   \n",
              "3                          0                               0   \n",
              "4                          0                               0   \n",
              "\n",
              "   user_n_games_bucket  user_game_win_rate_bucket  \n",
              "0                  100                       0.54  \n",
              "1                  100                       0.54  \n",
              "2                  100                       0.54  \n",
              "3                  100                       0.54  \n",
              "4                  100                       0.54  \n",
              "\n",
              "[5 rows x 1450 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load game data - adjust path as needed (first 10,000 rows for testing)\n",
        "data_path = \"../data/games/game_data_public.FDN.PremierDraft.csv.gz\"\n",
        "df_game = pd.read_csv(data_path, compression=\"gzip\", nrows=10000)\n",
        "print(f\"Loaded {len(df_game)} game records\")\n",
        "df_game.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test ETL Function\n",
        "\n",
        "Test the `etl_game()` function to extract relevant deckbuilding data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original records: 10000\n",
            "Processed records: 1684\n",
            "Columns before: 1450\n",
            "Columns after: 592\n"
          ]
        }
      ],
      "source": [
        "# Test the etl_game function\n",
        "processed_df = sd.etl_game(df_game)\n",
        "print(f\"Original records: {len(df_game)}\")\n",
        "print(f\"Processed records: {len(processed_df)}\")\n",
        "print(f\"Columns before: {len(df_game.columns)}\")\n",
        "print(f\"Columns after: {len(processed_df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Dataset Creation\n",
        "\n",
        "Test the `create_deckbuild_dataset()` function to create training data for deckbuilding models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with 1000 game records\n",
            "Columns before basic removal: 1450\n",
            "Removed 25 basic land columns\n",
            "Columns after basic removal: 1425\n",
            "After ETL: 163 records\n",
            "Found 281 deck columns\n",
            "Found 281 sideboard columns\n",
            "âœ… All basic lands successfully removed\n",
            "\n",
            "Sample deck composition (first few cards):\n",
            "  Abrade: 18 total copies across all decks\n",
            "  Abyssal Harvester: 5 total copies across all decks\n",
            "  Adventuring Gear: 0 total copies across all decks\n",
            "  Aegis Turtle: 6 total copies across all decks\n",
            "  Aetherize: 1 total copies across all decks\n",
            "\n",
            "Deck size statistics:\n",
            "  Mean deck size: 24.5\n",
            "  Std deck size: 1.3\n",
            "  Min/Max deck size: 23/28\n"
          ]
        }
      ],
      "source": [
        "# Test creating a deckbuilding dataset (using small sample for testing)\n",
        "# First let's create a small sample dataset to test with\n",
        "sample_size = 1000\n",
        "df_sample = df_game.head(sample_size)\n",
        "\n",
        "# Test the dataset creation with a small sample\n",
        "print(f\"Testing with {len(df_sample)} game records\")\n",
        "\n",
        "# Test basic removal\n",
        "print(f\"Columns before basic removal: {len(df_sample.columns)}\")\n",
        "df_sample_no_basics = sd.remove_basics_from_games(df_sample)\n",
        "print(f\"Columns after basic removal: {len(df_sample_no_basics.columns)}\")\n",
        "\n",
        "# Apply ETL to see the structure\n",
        "sample_processed = sd.etl_game(df_sample_no_basics)\n",
        "print(f\"After ETL: {len(sample_processed)} records\")\n",
        "\n",
        "# Look at the deck and sideboard columns\n",
        "deck_cols = [col for col in sample_processed.columns if col.startswith(\"deck_\")]\n",
        "sideboard_cols = [col for col in sample_processed.columns if col.startswith(\"sideboard_\")]\n",
        "\n",
        "print(f\"Found {len(deck_cols)} deck columns\")\n",
        "print(f\"Found {len(sideboard_cols)} sideboard columns\")\n",
        "\n",
        "# Check if any basic lands remain\n",
        "basic_names = [\"Forest\", \"Island\", \"Mountain\", \"Plains\", \"Swamp\"]\n",
        "remaining_basics = [col for col in deck_cols if any(basic in col for basic in basic_names)]\n",
        "if remaining_basics:\n",
        "    print(f\"Warning: Found remaining basic columns: {remaining_basics}\")\n",
        "else:\n",
        "    print(\"âœ… All basic lands successfully removed\")\n",
        "\n",
        "# Show some example card counts in decks\n",
        "if len(deck_cols) > 0:\n",
        "    print(\"\\nSample deck composition (first few cards):\")\n",
        "    for col in deck_cols[:5]:\n",
        "        card_name = col[5:]  # Remove \"deck_\" prefix\n",
        "        total_copies = sample_processed[col].sum()\n",
        "        print(f\"  {card_name}: {total_copies} total copies across all decks\")\n",
        "    \n",
        "    print(f\"\\nDeck size statistics:\")\n",
        "    deck_sizes = sample_processed[deck_cols].sum(axis=1)\n",
        "    print(f\"  Mean deck size: {deck_sizes.mean():.1f}\")\n",
        "    print(f\"  Std deck size: {deck_sizes.std():.1f}\")\n",
        "    print(f\"  Min/Max deck size: {deck_sizes.min()}/{deck_sizes.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing deckbuilding dataset creation logic...\n",
            "After filtering for good players: 159 records\n",
            "Pool data shape: (159, 281)\n",
            "Deck data shape: (159, 281)\n",
            "Created test dataset with 2 examples\n",
            "Sample pool vector shape: torch.Size([281])\n",
            "Sample deck vector shape: torch.Size([281])\n",
            "Sample pool sum (total cards available): 42.0\n",
            "Sample deck sum (cards in main deck): 24.0\n",
            "âœ… Dataset creation logic works correctly!\n"
          ]
        }
      ],
      "source": [
        "# Test the create_deckbuild_dataset function with a limited sample\n",
        "# Note: This would normally process the full dataset, but we'll test the functionality\n",
        "\n",
        "# For a real test, you would call:\n",
        "# train_path, val_path = sd.create_deckbuild_dataset(\"FDN\", \"Premier\", overwrite=True)\n",
        "\n",
        "# Instead, let's test the data processing logic manually to verify it works\n",
        "print(\"Testing deckbuilding dataset creation logic...\")\n",
        "\n",
        "# Simulate the key steps of create_deckbuild_dataset\n",
        "df_test = sample_processed.copy()\n",
        "\n",
        "# Filter for good players (similar to what the function does)\n",
        "min_winrate = df_test[\"user_n_games_bucket\"].apply(sd.get_min_winrate, p=0.40, stdev=1.5) # reduced p for testing\n",
        "df_filtered = df_test[df_test[\"user_game_win_rate_bucket\"] >= min_winrate]\n",
        "print(f\"After filtering for good players: {len(df_filtered)} records\")\n",
        "\n",
        "if len(df_filtered) > 0:\n",
        "    # Get deck and sideboard data\n",
        "    deck_data = df_filtered[sorted(deck_cols)].astype(int)\n",
        "    sideboard_data = df_filtered[sorted(sideboard_cols)].astype(int)\n",
        "    \n",
        "    # Create pool vectors (deck + sideboard)\n",
        "    pool_data = deck_data.values + sideboard_data.values\n",
        "    deck_vectors = deck_data.values\n",
        "    \n",
        "    print(f\"Pool data shape: {pool_data.shape}\")\n",
        "    print(f\"Deck data shape: {deck_vectors.shape}\")\n",
        "    \n",
        "    # Test creating a small DeckbuildDataset\n",
        "    cardnames = [col[5:] for col in sorted(deck_cols)]  # Remove \"deck_\" prefix\n",
        "    \n",
        "    if len(df_filtered) >= 2:  # Need at least 2 samples for dataset\n",
        "        test_dataset = sd.DeckbuildDataset(pool_data[:2], deck_vectors[:2], cardnames)\n",
        "        print(f\"Created test dataset with {len(test_dataset)} examples\")\n",
        "        \n",
        "        # Test accessing dataset items\n",
        "        pool_sample, deck_sample = test_dataset[0]\n",
        "        print(f\"Sample pool vector shape: {pool_sample.shape}\")\n",
        "        print(f\"Sample deck vector shape: {deck_sample.shape}\")\n",
        "        print(f\"Sample pool sum (total cards available): {pool_sample.sum().item()}\")\n",
        "        print(f\"Sample deck sum (cards in main deck): {deck_sample.sum().item()}\")\n",
        "        \n",
        "        print(\"âœ… Dataset creation logic works correctly!\")\n",
        "    else:\n",
        "        print(\"Not enough filtered samples to test dataset creation\")\n",
        "else:\n",
        "    print(\"No records passed the filtering criteria\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([281]) torch.Size([281])\n",
            "torch.Size([281]) torch.Size([281])\n"
          ]
        }
      ],
      "source": [
        "for x, y in test_dataset:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(41.), tensor(26.))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.sum(), y.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Deckbuilding Training Logic\n",
        "\n",
        "Test the core training sample creation and model training logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing deckbuild training sample creation...\n",
            "Original pool sum: 42.0\n",
            "Original deck sum: 24.0\n",
            "Current deck sum (after removing card): 23.0\n",
            "Available cards sum: 19.0\n",
            "Target card sum: 1.0\n",
            "Target card index: 134\n",
            "Reconstructed pool sum: 42.0\n",
            "Pool reconstruction matches: True\n",
            "âœ… Training sample creation logic works!\n"
          ]
        }
      ],
      "source": [
        "# Test the training sample creation logic\n",
        "print(\"Testing deckbuild training sample creation...\")\n",
        "\n",
        "import torch\n",
        "\n",
        "# Use the test dataset we created earlier\n",
        "if 'test_dataset' in locals() and len(test_dataset) > 0:\n",
        "    # Get a sample pool and deck\n",
        "    pool_sample, deck_sample = test_dataset[0]\n",
        "    \n",
        "    print(f\"Original pool sum: {pool_sample.sum().item()}\")\n",
        "    print(f\"Original deck sum: {deck_sample.sum().item()}\")\n",
        "    \n",
        "    # Test creating training samples\n",
        "    current_deck, available_cards, target_card = sd.create_deckbuild_training_sample(\n",
        "        pool_sample, deck_sample\n",
        "    )\n",
        "    \n",
        "    print(f\"Current deck sum (after removing card): {current_deck.sum().item()}\")\n",
        "    print(f\"Available cards sum: {available_cards.sum().item()}\")\n",
        "    print(f\"Target card sum: {target_card.sum().item()}\")\n",
        "    print(f\"Target card index: {torch.argmax(target_card).item()}\")\n",
        "    \n",
        "    # Verify the math: current_deck + available_cards should equal pool\n",
        "    reconstructed_pool = current_deck + available_cards\n",
        "    print(f\"Reconstructed pool sum: {reconstructed_pool.sum().item()}\")\n",
        "    print(f\"Pool reconstruction matches: {torch.allclose(pool_sample, reconstructed_pool)}\")\n",
        "    \n",
        "    print(\"âœ… Training sample creation logic works!\")\n",
        "else:\n",
        "    print(\"No test dataset available. Run the previous cells first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing deckbuild model training...\n",
            "Need at least 4 samples in test_dataset for training test\n"
          ]
        }
      ],
      "source": [
        "# Test creating and evaluating a small deckbuild model\n",
        "print(\"Testing deckbuild model training...\")\n",
        "\n",
        "if 'test_dataset' in locals() and len(test_dataset) >= 4:\n",
        "    from torch.utils.data import DataLoader\n",
        "    \n",
        "    # Create small test dataloaders with batch size >= 2 to avoid BatchNorm issues\n",
        "    train_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)  # Use batch_size=2 for BatchNorm\n",
        "    \n",
        "    # Create a small model for testing\n",
        "    cardnames = test_dataset.cardnames\n",
        "    test_network = sd.DraftNet(cardnames=cardnames, dropout_input=0.1)\n",
        "    \n",
        "    print(f\"Created test network with {len(cardnames)} cards\")\n",
        "    \n",
        "    # Test evaluation (before training)\n",
        "    print(\"Testing evaluation function...\")\n",
        "    initial_accuracy = sd.evaluate_deckbuild_model(val_loader, test_network)\n",
        "    print(f\"Initial accuracy: {initial_accuracy:.2f}%\")\n",
        "    \n",
        "    # Test a few training steps (not full training)\n",
        "    print(\"Testing training function (2 epochs only)...\")\n",
        "    \n",
        "    # Temporarily modify the training function for quick testing\n",
        "    import time\n",
        "    import torch.optim as optim\n",
        "    \n",
        "    loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "    optimizer = optim.Adam(test_network.parameters(), lr=0.01)\n",
        "    \n",
        "    for epoch in range(2):  # Just 2 epochs for testing\n",
        "        test_network.train()\n",
        "        epoch_loss = []\n",
        "        \n",
        "        for pool_batch, deck_batch in train_loader:\n",
        "            batch_size = pool_batch.shape[0]\n",
        "            \n",
        "            for i in range(batch_size):\n",
        "                pool_vector = pool_batch[i]\n",
        "                deck_vector = deck_batch[i]\n",
        "                \n",
        "                # Create training sample\n",
        "                current_deck, available_cards, target_card = sd.create_deckbuild_training_sample(\n",
        "                    pool_vector, deck_vector\n",
        "                )\n",
        "                \n",
        "                # Forward pass\n",
        "                optimizer.zero_grad()\n",
        "                current_deck_input = current_deck.unsqueeze(0).float()\n",
        "                available_cards_input = available_cards.unsqueeze(0).float()\n",
        "                target_input = target_card.unsqueeze(0).float()\n",
        "                \n",
        "                predicted_card = test_network(current_deck_input, available_cards_input)\n",
        "                loss = loss_fn(predicted_card, target_input).mean()\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss.append(loss.item())\n",
        "        \n",
        "        print(f\"Epoch {epoch}: Loss = {np.mean(epoch_loss):.4f}\")\n",
        "    \n",
        "    # Test evaluation after training\n",
        "    final_accuracy = sd.evaluate_deckbuild_model(val_loader, test_network)\n",
        "    print(f\"Final accuracy: {final_accuracy:.2f}%\")\n",
        "    \n",
        "    print(\"âœ… Deckbuild model training logic works!\")\n",
        "    \n",
        "else:\n",
        "    print(\"Need at least 4 samples in test_dataset for training test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Model Training (Optional)\n",
        "\n",
        "Uncomment and run the cell below to train a complete deckbuilding model on the full dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deckbuilding training and validation sets already exist. Skipping.\n",
            "Starting deckbuild model training. learning_rate=0.03\n",
            "Deckbuild validation accuracy = 6.1%\n",
            "\n",
            "Starting epoch 0  lr=0.03\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 400])",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Uncomment to train a full deckbuilding model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# WARNING: This will take significant time and computational resources\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m training_info \u001b[38;5;241m=\u001b[39m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_deckbuild_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_abbreviation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFDN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraft_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPremier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use existing dataset\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/Code/statistical-drafting/statisticaldrafting/deckbuild.py:454\u001b[0m, in \u001b[0;36mdefault_deckbuild_training_pipeline\u001b[0;34m(set_abbreviation, draft_mode, overwrite_dataset, dropout_input)\u001b[0m\n\u001b[1;32m    451\u001b[0m network \u001b[38;5;241m=\u001b[39m DraftNet(cardnames\u001b[38;5;241m=\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39mcardnames, dropout_input\u001b[38;5;241m=\u001b[39mdropout_input)\n\u001b[1;32m    453\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_abbreviation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdraft_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_deckbuild\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 454\u001b[0m network, training_info \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_deckbuild_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Log training information\u001b[39;00m\n\u001b[1;32m    462\u001b[0m _log_training_info(training_info)\n",
            "File \u001b[0;32m~/Desktop/Code/statistical-drafting/statisticaldrafting/deckbuild.py:369\u001b[0m, in \u001b[0;36mtrain_deckbuild_model\u001b[0;34m(train_dataloader, val_dataloader, network, learning_rate, experiment_name, model_folder)\u001b[0m\n\u001b[1;32m    366\u001b[0m available_cards_input \u001b[38;5;241m=\u001b[39m available_cards\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    367\u001b[0m target_input \u001b[38;5;241m=\u001b[39m target_card\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 369\u001b[0m predicted_card \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_deck_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_cards_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(predicted_card, target_input)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    372\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/Code/statistical-drafting/statisticaldrafting/model.py:51\u001b[0m, in \u001b[0;36mDraftNet.forward\u001b[0;34m(self, x, pack)\u001b[0m\n\u001b[1;32m     48\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_layer(x)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Apply BatchNorm1d (ensure correct shape: [batch_size, num_features])\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[1;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/functional.py:2815\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2803\u001b[0m         batch_norm,\n\u001b[1;32m   2804\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2812\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2813\u001b[0m     )\n\u001b[1;32m   2814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2815\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2818\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2819\u001b[0m     weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled,\n\u001b[1;32m   2827\u001b[0m )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/functional.py:2781\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2779\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2783\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 400])"
          ]
        }
      ],
      "source": [
        "# Uncomment to train a full deckbuilding model\n",
        "# WARNING: This will take significant time and computational resources\n",
        "\n",
        "training_info = sd.default_deckbuild_training_pipeline(\n",
        "    set_abbreviation=\"FDN\",\n",
        "    draft_mode=\"Premier\", \n",
        "    overwrite_dataset=False,  # Use existing dataset\n",
        "    dropout_input=0.6\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n",
        "print(f\"Final validation accuracy: {training_info['validation_accuracy']:.2f}%\")\n",
        "print(f\"Model saved as: {training_info['experiment_name']}.pt\")\n",
        "\n",
        "# The model will be saved as \"FDN_Premier_deckbuild.pt\" to avoid overwriting draft models\n",
        "\n",
        "# print(\"Full model training is commented out. Uncomment the code above to run.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Dataset Creation (Optional)\n",
        "\n",
        "Uncomment and run the cell below to create the full deckbuilding dataset. This will process all game data and create training/validation sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using input file ../data/games/game_data_public.FDN.PremierDraft.csv.gz\n",
            "Loading game data...\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to create the full deckbuilding dataset\n",
        "# WARNING: This will process the entire game dataset and may take some time\n",
        "import torch\n",
        "\n",
        "train_path, val_path = sd.create_deckbuild_dataset(\n",
        "    set_abbreviation=\"FDN\",\n",
        "    draft_mode=\"Premier\",\n",
        "    overwrite=True,\n",
        "    data_folder_games=\"../data/games/\",\n",
        "    data_folder_cards=\"../data/cards/\"\n",
        ")\n",
        "\n",
        "# print(f\"Training dataset saved to: {train_path}\")\n",
        "# print(f\"Validation dataset saved to: {val_path}\")\n",
        "\n",
        "# Test loading the created dataset\n",
        "train_dataset = torch.load(train_path, weights_only=False)\n",
        "val_dataset = torch.load(val_path, weights_only=False)\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "\n",
        "# Test a sample from the training set\n",
        "sample_pool, sample_deck = train_dataset[0]\n",
        "print(f\"Sample shapes - Pool: {sample_pool.shape}, Deck: {sample_deck.shape}\")\n",
        "\n",
        "# print(\"Full dataset creation is commented out. Uncomment the code above to run.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
